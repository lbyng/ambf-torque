import pickle
import numpy as np
import os

# åŠ è½½æ•°æ®é›†
with open('./data/features/dataset.pkl', 'rb') as f:
    dataset = pickle.load(f)

# åæ ‡å‡†åŒ–æµ‹è¯•æ•°æ®
y_test_scaled = dataset['y_test']
y_test = dataset['scaler_y'].inverse_transform(y_test_scaled)

# æ‰¾åˆ°å¼‚å¸¸å€¼çš„ä½ç½®
joint1_data = y_test[:, 0]
max_idx = np.argmax(joint1_data)
max_value = joint1_data[max_idx]

print(f"å¼‚å¸¸å€¼ä¿¡æ¯:")
print(f"  å€¼: {max_value:.6f} Nm")
print(f"  åœ¨æµ‹è¯•é›†ä¸­çš„ç´¢å¼•: {max_idx}")

# è·å–æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
test_files = dataset['metadata']['test_files']
print(f"\næµ‹è¯•é›†åŒ…å«çš„æ–‡ä»¶:")
for i, file in enumerate(test_files):
    print(f"  {i}: {file}")

# ç°åœ¨éœ€è¦åå‘è¿½è¸ªè¿™ä¸ªæ ·æœ¬æ¥è‡ªå“ªä¸ªæ–‡ä»¶
# ç”±äºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºçš„åºåˆ—æ•°é‡ä¸åŒï¼Œéœ€è¦é‡æ–°è®¡ç®—

print(f"\nå¼€å§‹å®šä½å¼‚å¸¸å€¼æ¥æºæ–‡ä»¶...")

# é‡æ–°å¤„ç†æµ‹è¯•æ–‡ä»¶ï¼Œè®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„åºåˆ—æ•°é‡
data_dir = input("è¯·è¾“å…¥åŸå§‹æ•°æ®ç›®å½•è·¯å¾„: ").strip()
sequence_length = dataset['metadata']['sequence_length']

cumulative_sequences = 0
found_file = None

for file_idx, file_name in enumerate(test_files):
    file_path = os.path.join(data_dir, file_name)
    
    try:
        # åŠ è½½æ–‡ä»¶
        data = np.loadtxt(file_path, delimiter=',')
        
        # è®¡ç®—è¿™ä¸ªæ–‡ä»¶èƒ½äº§ç”Ÿå¤šå°‘ä¸ªåºåˆ—
        if len(data) >= sequence_length:
            n_sequences = len(data) - sequence_length + 1
        else:
            n_sequences = 0
        
        print(f"æ–‡ä»¶ {file_name}: {len(data)} è¡Œæ•°æ® â†’ {n_sequences} ä¸ªåºåˆ—")
        
        # æ£€æŸ¥å¼‚å¸¸å€¼æ˜¯å¦åœ¨è¿™ä¸ªæ–‡ä»¶çš„èŒƒå›´å†…
        if cumulative_sequences <= max_idx < cumulative_sequences + n_sequences:
            found_file = file_name
            sequence_in_file = max_idx - cumulative_sequences
            
            print(f"\nğŸ¯ æ‰¾åˆ°äº†ï¼å¼‚å¸¸å€¼æ¥è‡ª:")
            print(f"  æ–‡ä»¶: {file_name}")
            print(f"  æ–‡ä»¶ä¸­çš„åºåˆ—ç´¢å¼•: {sequence_in_file}")
            print(f"  å¯¹åº”åŸå§‹æ•°æ®è¡Œ: {sequence_in_file + sequence_length - 1}")
            
            # éªŒè¯ï¼šæ£€æŸ¥è¿™ä¸ªæ–‡ä»¶çš„æ‰­çŸ©æ•°æ®
            tau_data = data[:, 114:117]  # tauåˆ—
            print(f"\næ–‡ä»¶ {file_name} çš„æ‰­çŸ©ç»Ÿè®¡:")
            print(f"  å…³èŠ‚1èŒƒå›´: [{tau_data[:, 0].min():.6f}, {tau_data[:, 0].max():.6f}]")
            print(f"  å…³èŠ‚2èŒƒå›´: [{tau_data[:, 1].min():.6f}, {tau_data[:, 1].max():.6f}]")
            print(f"  å…³èŠ‚3èŒƒå›´: [{tau_data[:, 2].min():.6f}, {tau_data[:, 2].max():.6f}]")
            
            # æ‰¾åˆ°å…·ä½“çš„å¼‚å¸¸è¡Œ
            max_row_in_file = np.argmax(tau_data[:, 0])
            print(f"  å¼‚å¸¸å€¼å…·ä½“ä½ç½®: ç¬¬ {max_row_in_file} è¡Œ")
            print(f"  å¼‚å¸¸å€¼: {tau_data[max_row_in_file, 0]:.6f}")
            
            break
        
        cumulative_sequences += n_sequences
        
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ {file_name} æ—¶å‡ºé”™: {e}")

if found_file:
    print(f"\nğŸ—‘ï¸  è¦åˆ é™¤çš„æ–‡ä»¶: {os.path.join(data_dir, found_file)}")
    print(f"\nåˆ é™¤å‘½ä»¤:")
    print(f"rm '{os.path.join(data_dir, found_file)}'")
    
    # è¯¢é—®æ˜¯å¦ç«‹å³åˆ é™¤
    choice = input(f"\næ˜¯å¦ç«‹å³åˆ é™¤æ–‡ä»¶ {found_file}? (y/N): ").strip().lower()
    if choice == 'y':
        try:
            os.remove(os.path.join(data_dir, found_file))
            print(f"âœ… æ–‡ä»¶ {found_file} å·²åˆ é™¤")
            print(f"è¯·é‡æ–°è¿è¡Œæ•°æ®é¢„å¤„ç†æ¥ç”Ÿæˆæ–°çš„æ•°æ®é›†")
        except Exception as e:
            print(f"âŒ åˆ é™¤å¤±è´¥: {e}")
    else:
        print("æ–‡ä»¶æœªåˆ é™¤")
else:
    print("âŒ æœªæ‰¾åˆ°å¼‚å¸¸å€¼æ¥æºæ–‡ä»¶")